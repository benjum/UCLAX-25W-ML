{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1dfcbb0",
   "metadata": {},
   "source": [
    "# Searching for meaning in our ML\n",
    "\n",
    "Understanding the particular code details of this notebook is secondary!  Your first goal should be to understand that there are techniques and tools for understanding your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5660469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfcc4e",
   "metadata": {},
   "source": [
    "We'll use an artificial dataset of three clusters using Scikit-Learn's `make_blobs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750afc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=300, centers=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycolors = ['red','green','blue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418eadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],\n",
    "         X[:,1],\n",
    "         c=[ycolors[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b718ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fe48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the feature coefficients\n",
    "print('intercepts:\\n',lr_model.intercept_)\n",
    "print('coefficients:\\n',lr_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the boundaries of predictions in feature space\n",
    "DecisionBoundaryDisplay.from_estimator(lr_model, \n",
    "                                       X,\n",
    "                                       response_method=\"predict\",\n",
    "                                       cmap=\"RdBu\", \n",
    "                                       alpha=0.5\n",
    ")\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5bb2b8",
   "metadata": {},
   "source": [
    "The model equation gives us direct access to these boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkgrid(a=0):\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], c=y);\n",
    "\n",
    "    # Create a grid of points\n",
    "    xbnd = np.linspace(-11, 8, 100)\n",
    "    ybnd = np.linspace(-11, 13, 100)\n",
    "    Xbnd, Ybnd = np.meshgrid(xbnd, ybnd)\n",
    "\n",
    "    # calculate softmax values across the grid\n",
    "    # and assign them into Z for visualization\n",
    "    Z = np.zeros((100,100))\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            denominator = 0\n",
    "            for k in range(3):\n",
    "              denominator += np.exp((lr_model.intercept_[k] +\n",
    "                                     xbnd[i] * lr_model.coef_[k,0] +\n",
    "                                     ybnd[j] * lr_model.coef_[k,1]))\n",
    "            probs = np.exp((lr_model.intercept_[a] +\n",
    "                            xbnd[i] * lr_model.coef_[a,0] +\n",
    "                            ybnd[j] * lr_model.coef_[a,1])) / denominator\n",
    "            Z[i,j] = probs\n",
    "\n",
    "    # Plot the grid points\n",
    "    plt.pcolormesh(Xbnd, Ybnd, Z.T, alpha=0.4, cmap='seismic', vmin=0.0, vmax=1.0)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "ipywidgets.interact(mkgrid, a=(0,2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8de5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "y_pred = lr_model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9484e1e9",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots\n",
    "These plots show the marginal effect of varying a given feature while keeping all other features constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_plot = [0, 1, (0, 1)]\n",
    "PartialDependenceDisplay.from_estimator(lr_model, \n",
    "                                        X_train, \n",
    "                                        features_to_plot,\n",
    "                                        target=2,\n",
    "                                        grid_resolution=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c379c6e",
   "metadata": {},
   "source": [
    "## LIME\n",
    "Local Interpretable Model-agnostic Explanations.  LIME takes an instance and generates perturbed samples around it, fits a local interpretable model (like a linear model), and quantifies the contribution of features in this local neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5792a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1870c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME explanation for a single instance\n",
    "explainer = lime_tabular.LimeTabularExplainer(X_train)\n",
    "\n",
    "# Choose a random instance for explanation\n",
    "random_instance_index = np.random.randint(0, len(X_test))\n",
    "instance_to_explain = X_test[random_instance_index]\n",
    "print('Instance coordinates:',instance_to_explain)\n",
    "\n",
    "# Explain the prediction using LIME\n",
    "explanation = explainer.explain_instance(instance_to_explain, \n",
    "                                         lr_model.predict_proba,\n",
    "                                         top_labels=3)\n",
    "\n",
    "# Display the explanation\n",
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510452e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limepoint():\n",
    "    \n",
    "    # LIME explanation for a single instance\n",
    "    explainer = lime_tabular.LimeTabularExplainer(X_train)\n",
    "\n",
    "    # Choose a random instance for explanation\n",
    "    random_instance_index = np.random.randint(0, len(X_test))\n",
    "    instance_to_explain = X_test[random_instance_index]\n",
    "    print('Instance coordinates:',instance_to_explain)\n",
    "\n",
    "    # Explain the prediction using LIME\n",
    "    explanation = explainer.explain_instance(instance_to_explain, \n",
    "                                             lr_model.predict_proba,\n",
    "                                             top_labels=3)\n",
    "\n",
    "    # Display the explanation\n",
    "    explanation.show_in_notebook()\n",
    "\n",
    "    DecisionBoundaryDisplay.from_estimator(lr_model, \n",
    "                                           X,\n",
    "                                           response_method=\"predict\",\n",
    "                                           cmap=\"RdBu\", \n",
    "                                           alpha=0.5\n",
    "    )\n",
    "    plt.scatter(X[:,0],\n",
    "                X[:,1],\n",
    "                c=[ycolors[i] for i in y])\n",
    "    plt.scatter(instance_to_explain[0],\n",
    "                instance_to_explain[1],\n",
    "                c='black',s=70)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "limepoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f5cbd",
   "metadata": {},
   "source": [
    "## SHAP\n",
    "SHapley Additive exPlanations is a \"game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions.\" -- see https://github.com/shap/shap and [linked papers](https://github.com/shap/shap?tab=readme-ov-file#citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4326c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d51e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eeccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(lr_model, X_train)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f068a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapbeeswarm(c=0):\n",
    "    shap.summary_plot(shap_values[:,:,c], X_test)\n",
    "ipywidgets.interact(shapbeeswarm,c=[0,1,2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b8db4",
   "metadata": {},
   "source": [
    "# Applying this back to handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d460630",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sklearn.datasets.load_digits()\n",
    "\n",
    "x = d.data\n",
    "y = d.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b97b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "lr_classifier = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c44eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier.fit(x_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84fe0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_classifier.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4200503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93076e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME explanation for a single instance\n",
    "explainer = lime_tabular.LimeTabularExplainer(x_scaled)\n",
    "\n",
    "# Choose a random instance for explanation\n",
    "random_instance_index = np.random.randint(0, len(x_test_scaled))\n",
    "instance_to_explain = x_test_scaled[random_instance_index]\n",
    "plt.imshow(instance_to_explain.reshape(8,8),cmap='binary')\n",
    "\n",
    "# Explain the prediction using LIME\n",
    "explanation = explainer.explain_instance(instance_to_explain, \n",
    "                                         lr_classifier.predict_proba,\n",
    "                                         top_labels=3)\n",
    "\n",
    "# Display the explanation\n",
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(lr_classifier, x_scaled)\n",
    "shap_values = explainer.shap_values(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whichfeature(feature_num = 43):\n",
    "    checkimage = np.zeros(64)\n",
    "    checkimage[feature_num] = 1\n",
    "    plt.imshow(checkimage.reshape(8,8), cmap='binary')\n",
    "    \n",
    "ipywidgets.interact(whichfeature, feature_num=(0,63));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dabd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_plot = [43, 21, (43, 21)]\n",
    "PartialDependenceDisplay.from_estimator(lr_classifier, \n",
    "                                        x_scaled, \n",
    "                                        features_to_plot,\n",
    "                                        target=2,\n",
    "                                        grid_resolution=50);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
